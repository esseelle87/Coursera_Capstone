{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geneva House Renting Consultancy\n",
    "Capstone Project, Applied Data Science Capstone by IBM/Coursera, Simone Lisi.\n",
    "\n",
    "## Scraping foursquare categories\n",
    "\n",
    "In this notebook, we will create a dictionary and store it in json files.\n",
    "This will be useful for grouping venues we will collect later (e.g. grouping restaurants like \n",
    "chinese, vietnamese, etc. as asian restaurants).\n",
    "\n",
    "The file \"dic_all_cat.json\" is a dictionary where each key is the categoryId of a \n",
    "<a href=\"https://developer.foursquare.com/docs/build-with-foursquare/categories/\">foursquare category</a> and the associated item is a list containing:\n",
    "\n",
    "categories_l[index][0] = 'foursquare category name';\n",
    "\n",
    "categories_l[index][1] = is an integer indicating the level of the category. Higher numbers indicate that the category is a subcategory;\n",
    "\n",
    "categories_l[index][-1] = is the categoryId, same as the key;\n",
    "\n",
    "categories_l[index][2:-1] = are the category ids of the parent categories; \n",
    "\n",
    "as a an example the list corresponding to 'Exhibit' (categoryId = '56aa371be4b08b9a8d573532')  would look like this:\n",
    "\n",
    "['Exhibit', 1.0, '56aa371be4b08b9a8d573532', '4d4b7104d754a06370d81259']\n",
    "\n",
    "where '4d4b7104d754a06370d81259' is the categoryId of 'Arts & Entertainment', its parent category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages. Set this cell to 'code' if needed.\n",
    "!conda install -c anaconda bs4 --yes\n",
    "\n",
    "!conda install -c conda-forge geopy --yes \n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.request as urllib2\n",
    "import random\n",
    "from random import choice\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "import folium # map rendering library\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlquery from Achim Tack, available on github.\n",
    "# https://github.com/ATack/GoogleTrafficParser/blob/master/google_traffic_parser.py\n",
    "def urlquery(url):\n",
    "    # function cycles randomly through different user agents and time intervals to simulate more natural queries\n",
    "    try:\n",
    "        sleeptime = float(random.randint(1,6))/5\n",
    "        time.sleep(sleeptime)\n",
    "\n",
    "        agents = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1309.0 Safari/537.17',\n",
    "        'Mozilla/5.0 (compatible; MSIE 10.6; Windows NT 6.1; Trident/5.0; InfoPath.2; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 2.0.50727) 3gpp-gba UNTRUSTED/1.0',\n",
    "        'Opera/12.80 (Windows NT 5.1; U; en) Presto/2.10.289 Version/12.02',\n",
    "        'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)',\n",
    "        'Mozilla/3.0',\n",
    "        'Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420+ (KHTML, like Gecko) Version/3.0 Mobile/1A543a Safari/419.3',\n",
    "        'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522+ (KHTML, like Gecko) Safari/419.3',\n",
    "        'Opera/9.00 (Windows NT 5.1; U; en)']\n",
    "\n",
    "        agent = choice(agents)\n",
    "        opener = urllib2.build_opener()\n",
    "        opener.addheaders = [('User-agent', agent)]\n",
    "\n",
    "        html = opener.open(url).read()\n",
    "        time.sleep(sleeptime)\n",
    "        \n",
    "        return html\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Something went wrong with Crawling:\\n%s' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### utility to explore a complex nested dictionary-list\n",
    "def structure_data(something, lev, keysearch = ''):\n",
    "    #print(something, 'is a ', type(something))\n",
    "    \n",
    "    if(type(something) is dict):\n",
    "        for key in something.keys():\n",
    "            if(key == keysearch):\n",
    "                print('\\nHEEEEEEEEERE!!!!!!!\\n')\n",
    "                \n",
    "            spaces = '    '*lev\n",
    "            print(spaces, key, 'is a ', type(something[key]))\n",
    "            structure_data(something[key], lev+1, keysearch)\n",
    "                \n",
    "    elif(type(something) is list):\n",
    "        for i, element in enumerate(something):\n",
    "            spaces = '    '*lev\n",
    "            print(spaces, i, 'is a ', type(element))\n",
    "            structure_data(element, lev+1, keysearch)\n",
    "    else:\n",
    "        spaces = '    '*lev\n",
    "        print(spaces, something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://developer.foursquare.com/docs/build-with-foursquare/categories/\n"
     ]
    }
   ],
   "source": [
    "url ='https://developer.foursquare.com/docs/build-with-foursquare/categories/'\n",
    "print(url)\n",
    "\n",
    "soup = BeautifulSoup(urlquery(url), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_soup = soup.prettify().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_l =[]\n",
    "for i, element in enumerate(list_soup):\n",
    "    if '<h3>' in element:\n",
    "        lv = ((len(list_soup[i+1]) - len(list_soup[i+1].lstrip()))-11)/3\n",
    "        name = list_soup[i+1]\n",
    "        cat_id = list_soup[i+4]\n",
    "        categories_l.append([name.lstrip().replace('&amp;', '&'), lv, cat_id.lstrip()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For each foursquare category, we retrive all parent categories and put them in a list\n",
    "### lvl is the category hierarichal level. Subcategories have higher levels\n",
    "\n",
    "i= len(categories_l)-1\n",
    "while i >= 0:\n",
    "    lvl = categories_l[i][1]\n",
    "    j = 1\n",
    "    while i-j >= 0:\n",
    "        lvl2 = categories_l[i-j][1]\n",
    "        if(lvl2 < lvl):\n",
    "            categories_l[i].insert(2, categories_l[i-j][2])\n",
    "            lvl = lvl2\n",
    "        if lvl2 == 0:\n",
    "            break\n",
    "        j += 1\n",
    "        \n",
    "    i -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arts & Entertainment', 0.0, '4d4b7104d754a06370d81259']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking few results\n",
    "categories_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exhibit', 1.0, '4d4b7104d754a06370d81259', '56aa371be4b08b9a8d573532']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking few results\n",
    "categories_l[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52e81612bcbc57f1066b79ea'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking few results\n",
    "categories_l[14][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing results in a dictionary\n",
    "dic_all_cat = {}\n",
    "for element in categories_l:\n",
    "    key = element[-1]\n",
    "    dic_all_cat[key] = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we save categories venues in a file for later use\n",
    "with open('dic_all_cat.json', 'w') as f:\n",
    "    json.dump(dic_all_cat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
